{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "da035fe58e548e8b1b7e8e89725b9e6bc745aa7b"
   },
   "source": [
    "# Humpback Whale Identification - CNN with Keras\n",
    "This kernel is based on [Anezka Kolaceke](https://www.kaggle.com/anezka)'s awesome work: [CNN with Keras for Humpback Whale ID](https://www.kaggle.com/anezka/cnn-with-keras-for-humpback-whale-id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "0d9c73ad23e6c2eae3028255ee00c3254fe66401"
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mplimg\n",
    "from matplotlib.pyplot import imshow\n",
    "import cv2\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "from keras.models import Model\n",
    "\n",
    "import keras.backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\", category=DeprecationWarning)\n",
    "IMAGE_HEIGHT = 256\n",
    "IMAGE_WIDTH = 256\n",
    "IMAGE_CHANNELS = 3\n",
    "NUM_CLASSES = 3500\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "46a8839e13a14eb8d16ea6823de9927ea63d5001"
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"train.csv\")\n",
    "train_df.head()\n",
    "NUM_CLASSES = train_df['Id'].nunique()\n",
    "print('Unique classes-',NUM_CLASSES)\n",
    "CLASS_DICT = {}\n",
    "CLASS_DICT_REV = {}\n",
    "ctr=0\n",
    "for whale_class in train_df['Id'].unique():\n",
    "    CLASS_DICT[whale_class] = ctr\n",
    "    CLASS_DICT_REV[str(ctr)] = whale_class\n",
    "    ctr+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "d_train_list = []\n",
    "d_test_list = []\n",
    "\n",
    "train_df.head()\n",
    "train_df = train_df[train_df.Id != 'new_whale']\n",
    "# print(train_df.groupby(['Id'])['Image'].apply(list).to_dict())\n",
    "splitting_dict = train_df.groupby(['Id'])['Image'].apply(list).to_dict()\n",
    "for whale_id in splitting_dict.keys():\n",
    "#     print('whale_id',whale_id,'Images',splitting_dict[whale_id])\n",
    "    if len(splitting_dict[whale_id]) > 1:\n",
    "        train_list, test_list = train_test_split(splitting_dict[whale_id], test_size=0.4)\n",
    "    else:\n",
    "        train_list = splitting_dict[whale_id]\n",
    "        test_list = splitting_dict[whale_id]\n",
    "#     print('Train_list',len(train_list),'test',len(test_list))\n",
    "    for imgs in train_list:\n",
    "        d_train_list.append([whale_id, imgs])\n",
    "    for imgs in test_list:\n",
    "        d_test_list.append([whale_id, imgs])\n",
    "        \n",
    "# print(d_train_list)\n",
    "d_train = pd.DataFrame(d_train_list,columns=['Id','Image'])\n",
    "d_test = pd.DataFrame(d_test_list,columns=['Id','Image'])\n",
    "# d_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(d_train.groupby(['Id'])['Image'].apply(list).to_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image(index, data, test):\n",
    "    if test==True:\n",
    "        img = cv2.imread('test/'+data['Image'].values[index].strip())\n",
    "    else:\n",
    "        img = cv2.imread('train/'+data['Image'].values[index].strip())\n",
    "    img = cv2.resize(img,(IMAGE_HEIGHT,IMAGE_WIDTH))\n",
    "    digit_class = CLASS_DICT[data['Id'].values[index]]\n",
    "    return img/255.0, digit_class\n",
    "\n",
    "def make_image_gen(data, batch_size = BATCH_SIZE, test=False):\n",
    "    while True:\n",
    "        # Randomize the indices to make an array\n",
    "        indices_arr = np.random.permutation(data.count()[0])\n",
    "        for batch in range(0, len(indices_arr), batch_size):\n",
    "            # slice out the current batch according to batch-size\n",
    "            current_batch = indices_arr[batch:(batch + batch_size)]\n",
    "\n",
    "            # initializing the arrays, x_train and y_train\n",
    "            image_arr = np.empty([0, IMAGE_HEIGHT, IMAGE_WIDTH, IMAGE_CHANNELS], dtype=np.float32)\n",
    "\n",
    "            y_train = np.empty([0], dtype=np.int32)\n",
    "\n",
    "            for i in current_batch:\n",
    "                # get image and its corresponding class(0,1,2,3,....,9)\n",
    "                image, image_class = get_image(i, data, test)\n",
    "                image = np.expand_dims(image,axis=0)\n",
    "                #print(image.shape)\n",
    "\n",
    "                # Appending them to existing batch\n",
    "                image_arr = np.append(image_arr, image, axis=0)\n",
    "                y_train = np.append(y_train, [image_class])\n",
    "                \n",
    "            y_train = to_categorical(y_train, num_classes=NUM_CLASSES)\n",
    "\n",
    "            yield (image_arr, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make train generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Dataset\n",
    "# d_train = pd.read_csv(os.path.join('train.csv'))\n",
    "train_gen = make_image_gen(d_train)\n",
    "train_x, train_y = next(train_gen)\n",
    "print('x', train_x.shape, train_x.min(), train_x.max())\n",
    "print('y', train_y.shape, train_y.min(), train_y.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make validation generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Dataset\n",
    "# d_test = pd.read_csv(os.path.join('test.csv'))\n",
    "test_gen = make_image_gen(d_train, BATCH_SIZE, True)\n",
    "test_x, test_y = next(train_gen)\n",
    "print('x', test_x.shape, test_x.min(), test_x.max())\n",
    "print('y', test_y.shape, test_y.min(), test_y.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Augment Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "dg_args = dict(featurewise_center = False, \n",
    "                  samplewise_center = False,\n",
    "                  brightness_range = [0.8,1.5],\n",
    "                  rotation_range = 5, \n",
    "                  width_shift_range = 0.05, \n",
    "                  height_shift_range = 0.05, \n",
    "                  shear_range = 0.01,  \n",
    "                  horizontal_flip = True, \n",
    "                  vertical_flip = False,\n",
    "                  fill_mode = 'nearest',\n",
    "                  data_format = 'channels_last')\n",
    "\n",
    "def create_aug_gen(in_gen, seed = None):\n",
    "    image_gen = ImageDataGenerator(**dg_args)\n",
    "    for in_x, in_y in in_gen:\n",
    "        # keep the seeds syncronized otherwise the augmentation to the images is different from the masks\n",
    "        g_x = image_gen.flow(255*in_x, \n",
    "                             batch_size = in_x.shape[0],\n",
    "                             shuffle=False)\n",
    "\n",
    "        yield next(g_x)/255.0, in_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Augmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "cur_gen = create_aug_gen(train_gen)\n",
    "t_x, t_y = next(cur_gen)\n",
    "print('x', t_x.shape, t_x.dtype, t_x.min(), t_x.max())\n",
    "print('y', t_y.shape, t_y.dtype, t_y.min(), t_y.max())\n",
    "# only keep first 20 samples to examine in detail\n",
    "t_x = t_x[:20]\n",
    "t_y = t_y[:20]\n",
    "fig = plt.figure(figsize=(15,12))\n",
    "for i in range(4):\n",
    "  for j in range(5):\n",
    "    plt.subplot(4,5,i*5 + j +1)\n",
    "    plt.title(np.argmax(t_y[i*5 + j]))\n",
    "    plt.imshow(np.reshape(t_x[i*5 + j],(IMAGE_HEIGHT,IMAGE_WIDTH,IMAGE_CHANNELS))[..., ::-1])\n",
    "    plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f46b24dbba74f22833cac6140e60348b15a8e047"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "def prepareImages(data, m, dataset):\n",
    "    print(\"Preparing images\")\n",
    "    X_train = np.zeros((m, IMAGE_HEIGHT, IMAGE_WIDTH, IMAGE_CHANNELS))\n",
    "    count = 0\n",
    "    \n",
    "    for fig in data['Image']:\n",
    "        #load images into images of size 100x100x3\n",
    "        img = image.load_img(\"./\"+dataset+\"/\"+fig, target_size=(IMAGE_HEIGHT, IMAGE_WIDTH, IMAGE_CHANNELS))\n",
    "        x = image.img_to_array(img)\n",
    "        x = preprocess_input(x)\n",
    "\n",
    "        X_train[count] = x\n",
    "        if (count%500 == 0):\n",
    "            print(\"Processing image: \", count+1, \", \", fig)\n",
    "        count += 1\n",
    "    \n",
    "    return X_train\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "6587a101b58af064af0f9c60a1070c6c8f52d45f"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "def prepare_labels(y):\n",
    "    values = np.array(y)\n",
    "    label_encoder = LabelEncoder()\n",
    "    integer_encoded = label_encoder.fit_transform(values)\n",
    "    # print(integer_encoded)\n",
    "\n",
    "    onehot_encoder = OneHotEncoder(sparse=False)\n",
    "    integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
    "    onehot_encoded = onehot_encoder.fit_transform(integer_encoded)\n",
    "    # print(onehot_encoded)\n",
    "\n",
    "    y = onehot_encoded\n",
    "    # print(y.shape)\n",
    "    return y, label_encoder\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "4afe4128a0cd6859848c8a80686208082d647c39"
   },
   "outputs": [],
   "source": [
    "# X = prepareImages(train_df, train_df.shape[0], \"train\")\n",
    "# X /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "675924f8863aef27cf90dc668e0a68cd609dfc1c"
   },
   "outputs": [],
   "source": [
    "# y, label_encoder = prepare_labels(train_df['Id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "14d243b19023e830b636bea16679e13bc40deae6"
   },
   "outputs": [],
   "source": [
    "# y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SE Inception model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from __future__ import absolute_import\n",
    "import warnings\n",
    "\n",
    "from keras.applications import inception_v3\n",
    "from keras.models import Model\n",
    "from keras.layers import GlobalAveragePooling2D, Reshape, Dense, multiply, Permute\n",
    "from keras import backend as K\n",
    "from keras import layers\n",
    "from keras.applications.imagenet_utils import decode_predictions\n",
    "from keras_applications.imagenet_utils import _obtain_input_shape\n",
    "from keras.engine.topology import get_source_inputs\n",
    "from keras.utils.data_utils import get_file\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "\n",
    "def SE_block(input_layer, ratio=16, is_channel_first=False):\n",
    "    ''' Create a squeeze-excite block\n",
    "    Args:\n",
    "        input_layer: input tensor\n",
    "        filters: number of output filters\n",
    "        k: width factor\n",
    "    Returns: a keras tensor\n",
    "    '''\n",
    "    init = input_layer\n",
    "    channel_axis = 1 if K.image_data_format() == 'channels_first' else -1\n",
    "    filters = init._keras_shape[channel_axis]\n",
    "    layer_in_shape = (1, 1, filters)\n",
    "\n",
    "    layer = GlobalAveragePooling2D()(init)\n",
    "    layer = Reshape(layer_in_shape)(layer)\n",
    "    layer = Dense(filters // ratio, activation='relu', kernel_initializer='he_normal', use_bias=False)(layer)\n",
    "    layer = Dense(filters, activation='sigmoid', kernel_initializer='he_normal', use_bias=False)(layer)\n",
    "\n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        layer = Permute((3, 1, 2))(layer)\n",
    "\n",
    "    out = multiply([init, layer])\n",
    "    return out\n",
    "\n",
    "# The InceptionV3 model code is taken from keras_applications/inception_v3.py\n",
    "# https://github.com/keras-team/keras-applications/blob/master/keras_applications/inception_v3.py\n",
    "\n",
    "def conv2d_bn(x,\n",
    "              filters,\n",
    "              num_row,\n",
    "              num_col,\n",
    "              padding='same',\n",
    "              strides=(1, 1),\n",
    "              name=None):\n",
    "    \"\"\"Utility function to apply conv + BN.\n",
    "    # Arguments\n",
    "        x: input tensor.\n",
    "        filters: filters in `Conv2D`.\n",
    "        num_row: height of the convolution kernel.\n",
    "        num_col: width of the convolution kernel.\n",
    "        padding: padding mode in `Conv2D`.\n",
    "        strides: strides in `Conv2D`.\n",
    "        name: name of the ops; will become `name + '_conv'`\n",
    "            for the convolution and `name + '_bn'` for the\n",
    "            batch norm layer.\n",
    "    # Returns\n",
    "        Output tensor after applying `Conv2D` and `BatchNormalization`.\n",
    "    \"\"\"\n",
    "    if name is not None:\n",
    "        bn_name = name + '_bn'\n",
    "        conv_name = name + '_conv'\n",
    "    else:\n",
    "        bn_name = None\n",
    "        conv_name = None\n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        bn_axis = 1\n",
    "    else:\n",
    "        bn_axis = 3\n",
    "    x = layers.Conv2D(\n",
    "        filters, (num_row, num_col),\n",
    "        strides=strides,\n",
    "        padding=padding,\n",
    "        use_bias=False,\n",
    "        name=conv_name)(x)\n",
    "    x = layers.BatchNormalization(axis=bn_axis, scale=False, name=bn_name)(x)\n",
    "    x = layers.Activation('relu', name=name)(x)\n",
    "    return x\n",
    "\n",
    "def SE_Inception(include_top=True,\n",
    "                  weights=None,\n",
    "                  input_tensor=None,\n",
    "                  input_shape=None,\n",
    "                  pooling=None,\n",
    "                  classes=1000):\n",
    "    \"\"\"Instantiates the Inception v3 architecture with Squeeze-Excite blocks.\n",
    "    Optionally loads weights pre-trained on ImageNet.\n",
    "    Note that the data format convention used by the model is\n",
    "    the one specified in your Keras config at `~/.keras/keras.json`.\n",
    "    # Arguments\n",
    "        include_top: whether to include the fully-connected\n",
    "            layer at the top of the network.\n",
    "        weights: one of `None` (random initialization),\n",
    "              'imagenet' (pre-training on ImageNet),\n",
    "              or the path to the weights file to be loaded.\n",
    "        input_tensor: optional Keras tensor (i.e. output of `layers.Input()`)\n",
    "            to use as image input for the model.\n",
    "        input_shape: optional shape tuple, only to be specified\n",
    "            if `include_top` is False (otherwise the input shape\n",
    "            has to be `(299, 299, 3)` (with `channels_last` data format)\n",
    "            or `(3, 299, 299)` (with `channels_first` data format).\n",
    "            It should have exactly 3 inputs channels,\n",
    "            and width and height should be no smaller than 139.\n",
    "            E.g. `(150, 150, 3)` would be one valid value.\n",
    "        pooling: Optional pooling mode for feature extraction\n",
    "            when `include_top` is `False`.\n",
    "            - `None` means that the output of the model will be\n",
    "                the 4D tensor output of the\n",
    "                last convolutional layer.\n",
    "            - `avg` means that global average pooling\n",
    "                will be applied to the output of the\n",
    "                last convolutional layer, and thus\n",
    "                the output of the model will be a 2D tensor.\n",
    "            - `max` means that global max pooling will\n",
    "                be applied.\n",
    "        classes: optional number of classes to classify images\n",
    "            into, only to be specified if `include_top` is True, and\n",
    "            if no `weights` argument is specified.\n",
    "    # Returns\n",
    "        A Keras model instance.\n",
    "    # Raises\n",
    "        ValueError: in case of invalid argument for `weights`,\n",
    "            or invalid input shape.\n",
    "    \"\"\"\n",
    "\n",
    "    if not (weights in {'imagenet', None} or os.path.exists(weights)):\n",
    "        raise ValueError('The `weights` argument should be either '\n",
    "                         '`None` (random initialization), `imagenet` '\n",
    "                         '(pre-training on ImageNet), '\n",
    "                         'or the path to the weights file to be loaded.')\n",
    "\n",
    "    if weights == 'imagenet' and include_top and classes != 1000:\n",
    "        raise ValueError('If using `weights` as `\"imagenet\"` with `include_top`'\n",
    "                         ' as true, `classes` should be 1000')\n",
    "\n",
    "    # Determine proper input shape\n",
    "    input_shape = _obtain_input_shape(\n",
    "        input_shape,\n",
    "        default_size=299,\n",
    "        min_size=75,\n",
    "        data_format=K.image_data_format(),\n",
    "        require_flatten=False,\n",
    "        weights=weights)\n",
    "\n",
    "    if input_tensor is None:\n",
    "        img_input = layers.Input(shape=input_shape)\n",
    "    else:\n",
    "        if not K.is_keras_tensor(input_tensor):\n",
    "            img_input = layers.Input(tensor=input_tensor, shape=input_shape)\n",
    "        else:\n",
    "            img_input = input_tensor\n",
    "\n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        channel_axis = 1\n",
    "    else:\n",
    "        channel_axis = 3\n",
    "\n",
    "    x = conv2d_bn(img_input, 32, 3, 3, strides=(2, 2), padding='valid')\n",
    "    x = conv2d_bn(x, 32, 3, 3, padding='valid')\n",
    "    x = conv2d_bn(x, 64, 3, 3)\n",
    "    x = layers.MaxPooling2D((3, 3), strides=(2, 2))(x)\n",
    "\n",
    "    x = conv2d_bn(x, 80, 1, 1, padding='valid')\n",
    "    x = conv2d_bn(x, 192, 3, 3, padding='valid')\n",
    "    x = layers.MaxPooling2D((3, 3), strides=(2, 2))(x)\n",
    "\n",
    "    # mixed 0, 1, 2: 35 x 35 x 256\n",
    "    branch1x1 = conv2d_bn(x, 64, 1, 1)\n",
    "\n",
    "    branch5x5 = conv2d_bn(x, 48, 1, 1)\n",
    "    branch5x5 = conv2d_bn(branch5x5, 64, 5, 5)\n",
    "\n",
    "    branch3x3dbl = conv2d_bn(x, 64, 1, 1)\n",
    "    branch3x3dbl = conv2d_bn(branch3x3dbl, 96, 3, 3)\n",
    "    branch3x3dbl = conv2d_bn(branch3x3dbl, 96, 3, 3)\n",
    "\n",
    "    branch_pool = layers.AveragePooling2D((3, 3),\n",
    "                                          strides=(1, 1),\n",
    "                                          padding='same')(x)\n",
    "    branch_pool = conv2d_bn(branch_pool, 32, 1, 1)\n",
    "    x = layers.concatenate(\n",
    "        [branch1x1, branch5x5, branch3x3dbl, branch_pool],\n",
    "        axis=channel_axis,\n",
    "        name='mixed0')\n",
    "\n",
    "    # squeeze and excite block ----------------------------------------------\n",
    "    x = SE_block(x)\n",
    "    #------------------------------------------------------------------------\n",
    "\n",
    "    # mixed 1: 35 x 35 x 256\n",
    "    branch1x1 = conv2d_bn(x, 64, 1, 1)\n",
    "\n",
    "    branch5x5 = conv2d_bn(x, 48, 1, 1)\n",
    "    branch5x5 = conv2d_bn(branch5x5, 64, 5, 5)\n",
    "\n",
    "    branch3x3dbl = conv2d_bn(x, 64, 1, 1)\n",
    "    branch3x3dbl = conv2d_bn(branch3x3dbl, 96, 3, 3)\n",
    "    branch3x3dbl = conv2d_bn(branch3x3dbl, 96, 3, 3)\n",
    "\n",
    "    branch_pool = layers.AveragePooling2D((3, 3),\n",
    "                                          strides=(1, 1),\n",
    "                                          padding='same')(x)\n",
    "    branch_pool = conv2d_bn(branch_pool, 64, 1, 1)\n",
    "    x = layers.concatenate(\n",
    "        [branch1x1, branch5x5, branch3x3dbl, branch_pool],\n",
    "        axis=channel_axis,\n",
    "        name='mixed1')\n",
    "\n",
    "    # squeeze and excite block ----------------------------------------------\n",
    "    x = SE_block(x)\n",
    "    #------------------------------------------------------------------------\n",
    "\n",
    "    # mixed 2: 35 x 35 x 256\n",
    "    branch1x1 = conv2d_bn(x, 64, 1, 1)\n",
    "\n",
    "    branch5x5 = conv2d_bn(x, 48, 1, 1)\n",
    "    branch5x5 = conv2d_bn(branch5x5, 64, 5, 5)\n",
    "\n",
    "    branch3x3dbl = conv2d_bn(x, 64, 1, 1)\n",
    "    branch3x3dbl = conv2d_bn(branch3x3dbl, 96, 3, 3)\n",
    "    branch3x3dbl = conv2d_bn(branch3x3dbl, 96, 3, 3)\n",
    "\n",
    "    branch_pool = layers.AveragePooling2D((3, 3),\n",
    "                                          strides=(1, 1),\n",
    "                                          padding='same')(x)\n",
    "    branch_pool = conv2d_bn(branch_pool, 64, 1, 1)\n",
    "    x = layers.concatenate(\n",
    "        [branch1x1, branch5x5, branch3x3dbl, branch_pool],\n",
    "        axis=channel_axis,\n",
    "        name='mixed2')\n",
    "\n",
    "    # squeeze and excite block ----------------------------------------------\n",
    "    x = SE_block(x)\n",
    "    #------------------------------------------------------------------------\n",
    "\n",
    "    # mixed 3: 17 x 17 x 768\n",
    "    branch3x3 = conv2d_bn(x, 384, 3, 3, strides=(2, 2), padding='valid')\n",
    "\n",
    "    branch3x3dbl = conv2d_bn(x, 64, 1, 1)\n",
    "    branch3x3dbl = conv2d_bn(branch3x3dbl, 96, 3, 3)\n",
    "    branch3x3dbl = conv2d_bn(\n",
    "        branch3x3dbl, 96, 3, 3, strides=(2, 2), padding='valid')\n",
    "\n",
    "    branch_pool = layers.MaxPooling2D((3, 3), strides=(2, 2))(x)\n",
    "    x = layers.concatenate(\n",
    "        [branch3x3, branch3x3dbl, branch_pool],\n",
    "        axis=channel_axis,\n",
    "        name='mixed3')\n",
    "\n",
    "    # squeeze and excite block ----------------------------------------------\n",
    "    x = SE_block(x)\n",
    "    #------------------------------------------------------------------------\n",
    "\n",
    "    # mixed 4: 17 x 17 x 768\n",
    "    branch1x1 = conv2d_bn(x, 192, 1, 1)\n",
    "\n",
    "    branch7x7 = conv2d_bn(x, 128, 1, 1)\n",
    "    branch7x7 = conv2d_bn(branch7x7, 128, 1, 7)\n",
    "    branch7x7 = conv2d_bn(branch7x7, 192, 7, 1)\n",
    "\n",
    "    branch7x7dbl = conv2d_bn(x, 128, 1, 1)\n",
    "    branch7x7dbl = conv2d_bn(branch7x7dbl, 128, 7, 1)\n",
    "    branch7x7dbl = conv2d_bn(branch7x7dbl, 128, 1, 7)\n",
    "    branch7x7dbl = conv2d_bn(branch7x7dbl, 128, 7, 1)\n",
    "    branch7x7dbl = conv2d_bn(branch7x7dbl, 192, 1, 7)\n",
    "\n",
    "    branch_pool = layers.AveragePooling2D((3, 3),\n",
    "                                          strides=(1, 1),\n",
    "                                          padding='same')(x)\n",
    "    branch_pool = conv2d_bn(branch_pool, 192, 1, 1)\n",
    "    x = layers.concatenate(\n",
    "        [branch1x1, branch7x7, branch7x7dbl, branch_pool],\n",
    "        axis=channel_axis,\n",
    "        name='mixed4')\n",
    "\n",
    "    # squeeze and excite block ----------------------------------------------\n",
    "    x = SE_block(x)\n",
    "    #------------------------------------------------------------------------\n",
    "\n",
    "    # mixed 5, 6: 17 x 17 x 768\n",
    "    for i in range(2):\n",
    "        branch1x1 = conv2d_bn(x, 192, 1, 1)\n",
    "\n",
    "        branch7x7 = conv2d_bn(x, 160, 1, 1)\n",
    "        branch7x7 = conv2d_bn(branch7x7, 160, 1, 7)\n",
    "        branch7x7 = conv2d_bn(branch7x7, 192, 7, 1)\n",
    "\n",
    "        branch7x7dbl = conv2d_bn(x, 160, 1, 1)\n",
    "        branch7x7dbl = conv2d_bn(branch7x7dbl, 160, 7, 1)\n",
    "        branch7x7dbl = conv2d_bn(branch7x7dbl, 160, 1, 7)\n",
    "        branch7x7dbl = conv2d_bn(branch7x7dbl, 160, 7, 1)\n",
    "        branch7x7dbl = conv2d_bn(branch7x7dbl, 192, 1, 7)\n",
    "\n",
    "        branch_pool = layers.AveragePooling2D(\n",
    "            (3, 3), strides=(1, 1), padding='same')(x)\n",
    "        branch_pool = conv2d_bn(branch_pool, 192, 1, 1)\n",
    "        x = layers.concatenate(\n",
    "            [branch1x1, branch7x7, branch7x7dbl, branch_pool],\n",
    "            axis=channel_axis,\n",
    "            name='mixed' + str(5 + i))\n",
    "\n",
    "    # squeeze and excite block ----------------------------------------------\n",
    "    x = SE_block(x)\n",
    "    #------------------------------------------------------------------------\n",
    "\n",
    "    # mixed 7: 17 x 17 x 768\n",
    "    branch1x1 = conv2d_bn(x, 192, 1, 1)\n",
    "\n",
    "    branch7x7 = conv2d_bn(x, 192, 1, 1)\n",
    "    branch7x7 = conv2d_bn(branch7x7, 192, 1, 7)\n",
    "    branch7x7 = conv2d_bn(branch7x7, 192, 7, 1)\n",
    "\n",
    "    branch7x7dbl = conv2d_bn(x, 192, 1, 1)\n",
    "    branch7x7dbl = conv2d_bn(branch7x7dbl, 192, 7, 1)\n",
    "    branch7x7dbl = conv2d_bn(branch7x7dbl, 192, 1, 7)\n",
    "    branch7x7dbl = conv2d_bn(branch7x7dbl, 192, 7, 1)\n",
    "    branch7x7dbl = conv2d_bn(branch7x7dbl, 192, 1, 7)\n",
    "\n",
    "    branch_pool = layers.AveragePooling2D((3, 3),\n",
    "                                          strides=(1, 1),\n",
    "                                          padding='same')(x)\n",
    "    branch_pool = conv2d_bn(branch_pool, 192, 1, 1)\n",
    "    x = layers.concatenate(\n",
    "        [branch1x1, branch7x7, branch7x7dbl, branch_pool],\n",
    "        axis=channel_axis,\n",
    "        name='mixed7')\n",
    "\n",
    "    # squeeze and excite block ----------------------------------------------\n",
    "    x = SE_block(x)\n",
    "    #------------------------------------------------------------------------\n",
    "\n",
    "    # mixed 8: 8 x 8 x 1280\n",
    "    branch3x3 = conv2d_bn(x, 192, 1, 1)\n",
    "    branch3x3 = conv2d_bn(branch3x3, 320, 3, 3,\n",
    "                          strides=(2, 2), padding='valid')\n",
    "\n",
    "    branch7x7x3 = conv2d_bn(x, 192, 1, 1)\n",
    "    branch7x7x3 = conv2d_bn(branch7x7x3, 192, 1, 7)\n",
    "    branch7x7x3 = conv2d_bn(branch7x7x3, 192, 7, 1)\n",
    "    branch7x7x3 = conv2d_bn(\n",
    "        branch7x7x3, 192, 3, 3, strides=(2, 2), padding='valid')\n",
    "\n",
    "    branch_pool = layers.MaxPooling2D((3, 3), strides=(2, 2))(x)\n",
    "    x = layers.concatenate(\n",
    "        [branch3x3, branch7x7x3, branch_pool],\n",
    "        axis=channel_axis,\n",
    "        name='mixed8')\n",
    "\n",
    "    # squeeze and excite block ----------------------------------------------\n",
    "    x = SE_block(x)\n",
    "    #------------------------------------------------------------------------\n",
    "\n",
    "    # mixed 9: 8 x 8 x 2048\n",
    "    for i in range(2):\n",
    "        branch1x1 = conv2d_bn(x, 320, 1, 1)\n",
    "\n",
    "        branch3x3 = conv2d_bn(x, 384, 1, 1)\n",
    "        branch3x3_1 = conv2d_bn(branch3x3, 384, 1, 3)\n",
    "        branch3x3_2 = conv2d_bn(branch3x3, 384, 3, 1)\n",
    "        branch3x3 = layers.concatenate(\n",
    "            [branch3x3_1, branch3x3_2],\n",
    "            axis=channel_axis,\n",
    "            name='mixed9_' + str(i))\n",
    "\n",
    "        branch3x3dbl = conv2d_bn(x, 448, 1, 1)\n",
    "        branch3x3dbl = conv2d_bn(branch3x3dbl, 384, 3, 3)\n",
    "        branch3x3dbl_1 = conv2d_bn(branch3x3dbl, 384, 1, 3)\n",
    "        branch3x3dbl_2 = conv2d_bn(branch3x3dbl, 384, 3, 1)\n",
    "        branch3x3dbl = layers.concatenate(\n",
    "            [branch3x3dbl_1, branch3x3dbl_2], axis=channel_axis)\n",
    "\n",
    "        branch_pool = layers.AveragePooling2D(\n",
    "            (3, 3), strides=(1, 1), padding='same')(x)\n",
    "        branch_pool = conv2d_bn(branch_pool, 192, 1, 1)\n",
    "        x = layers.concatenate(\n",
    "            [branch1x1, branch3x3, branch3x3dbl, branch_pool],\n",
    "            axis=channel_axis,\n",
    "            name='mixed' + str(9 + i))\n",
    "\n",
    "        # squeeze and excite block ----------------------------------------------\n",
    "        x = SE_block(x)\n",
    "        #------------------------------------------------------------------------\n",
    "\n",
    "    if include_top:\n",
    "        # Classification block\n",
    "        x = layers.GlobalAveragePooling2D(name='avg_pool')(x)\n",
    "        x = layers.Dense(classes, activation='softmax', name='predictions')(x)\n",
    "    else:\n",
    "        if pooling == 'avg':\n",
    "            x = layers.GlobalAveragePooling2D()(x)\n",
    "        elif pooling == 'max':\n",
    "            x = layers.GlobalMaxPooling2D()(x)\n",
    "\n",
    "    # Ensure that the model takes into account\n",
    "    # any potential predecessors of `input_tensor`.\n",
    "    if input_tensor is not None:\n",
    "        inputs = get_source_inputs(input_tensor)\n",
    "    else:\n",
    "        inputs = img_input\n",
    "    # Create model.\n",
    "    model = Model(inputs, x, name='inception_v3')\n",
    "    model.summary()\n",
    "    return model\n",
    "    \n",
    "def preprocess_input(img):\n",
    "    img /= 255.\n",
    "    img -= 0.5\n",
    "    img *= 2.\n",
    "    return img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e7af799d186a1b97b6aa325d7d576a1fb55a6c5d"
   },
   "outputs": [],
   "source": [
    "model = SE_Inception(include_top=True, weights=None, input_shape=(IMAGE_HEIGHT, IMAGE_WIDTH, IMAGE_CHANNELS),\n",
    "                     classes=10)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=\"adam\", metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_path = \"{}_weights.best.hdf5\".format('SE_Inception_model')\n",
    "earlyStopper = EarlyStopping(monitor=\"val_loss\", mode=\"min\", patience=6)\n",
    "checkPointer = ModelCheckpoint(weight_path, monitor='val_loss',\n",
    "                               verbose=1, save_best_only=True, mode='min', save_weights_only=True)\n",
    "reduceLROnPlat = ReduceLROnPlateau(monitor='val_loss', factor=0.8, patience=3,\n",
    "                                   verbose=1, mode='min', min_delta=0.0001, cooldown=2, min_lr=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "169f45e150c3a584e0f655a8eda523e0675da63a"
   },
   "outputs": [],
   "source": [
    "# history = model.fit(X, y, epochs=100, batch_size=64, verbose=1,\n",
    "#                     callbacks=[earlyStopper, reduceLROnPlat, checkPointer])\n",
    "print('Training started....')\n",
    "\n",
    "train_steps = len(d_train)//BATCH_SIZE\n",
    "val_steps = len(d_test)//BATCH_SIZE\n",
    "\n",
    "history = model.fit_generator(\n",
    "    train_gen,\n",
    "    steps_per_epoch=train_steps,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=test_gen,\n",
    "    validation_steps=val_steps,\n",
    "    verbose=1,\n",
    "    callbacks=callbacks_list,\n",
    "    workers=1\n",
    ")\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "7bca48a1d0963cbf70685b75431435cef9499895"
   },
   "outputs": [],
   "source": [
    "plt.plot(history.history['acc'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "debe961c93b72bef151d9aad3ca2cb500ee00aaa"
   },
   "outputs": [],
   "source": [
    "test = os.listdir(\"test/\")\n",
    "print(len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "72ed8198f519f7b1ae3efbc688933c78d8cdd0e4"
   },
   "outputs": [],
   "source": [
    "col = ['Image']\n",
    "test_df = pd.DataFrame(test, columns=col)\n",
    "test_df['Id'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "52262195fc0b8755cff78bf8c98e6116d50f79af"
   },
   "outputs": [],
   "source": [
    "X = prepareImages(test_df, test_df.shape[0], \"test\")\n",
    "X /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "88c8d8ff98fbdb1df4218abb6bd51889e855a6fb"
   },
   "outputs": [],
   "source": [
    "predictions = model.predict(np.array(X), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "66f0bdde31b8c7847916268aa82d9a1bdc9c0658"
   },
   "outputs": [],
   "source": [
    "for i, pred in enumerate(predictions):\n",
    "#     test_df.loc[i, 'Id'] = ' '.join(label_encoder.inverse_transform(pred.argsort()[-5:][::-1]))\n",
    "      test_df.loc[i,'Id'] = CLASS_DICT_REV[np.argmax(pred)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "09d7c1eb9b554e4e580b0c3c7eb609c15636892d"
   },
   "outputs": [],
   "source": [
    "test_df.head(10)\n",
    "test_df.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
